{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "sys.path.append(\"../../src\")\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from example_lorenz import get_lorenz_data, generate_lorenz_data\n",
    "#from autoencoder import full_network\n",
    "#from training import create_feed_dictionary\n",
    "#from sindy_utils import sindy_simulate\n",
    "#from sindy_utils import sindy_library\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from shallowNet.shallowNet import shallowNet, DenseTranspose\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Flatten\n",
    "from typing import List, Tuple, Union\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "data_path = os.getcwd() + '/'\n",
    "save_name = 'model1'\n",
    "params = pickle.load(open(data_path + save_name + '_params.pkl', 'rb'))\n",
    "params['save_name'] = data_path + save_name\n",
    "\n",
    "t = np.arange(0,20,.01)\n",
    "z0 = np.array([[-8,7,27]])\n",
    "\n",
    "test_data = generate_lorenz_data(z0, t, params['input_dim'], linear=False, normalization=np.array([1/40,1/40,1/40]))\n",
    "test_data['x'] = test_data['x'].reshape((-1,params['input_dim']))\n",
    "test_data['dx'] = test_data['dx'].reshape((-1,params['input_dim']))\n",
    "test_data['z'] = test_data['z'].reshape((-1,params['latent_dim']))\n",
    "test_data['dz'] = test_data['dz'].reshape((-1,params['latent_dim']))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "test_data.keys()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['t', 'y_spatial', 'modes', 'x', 'dx', 'ddx', 'z', 'dz', 'ddz', 'sindy_coefficients'])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "test_data['x'][:,0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc9dc93df98>]"
      ]
     },
     "metadata": {},
     "execution_count": 13
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "z = tf.stack(test_data['x'][:16])\n",
    "latent_dim = 3\n",
    "poly_order = 2\n",
    "include_sine = True\n",
    "library = [tf.ones(tf.shape(z)[0])]\n",
    "\n",
    "def sindy_library_tf(z, latent_dim, poly_order, include_sine=False):\n",
    "    \"\"\"\n",
    "    !!!! TF2 - VERSION !!!!\n",
    "    \n",
    "    Build the SINDy library.\n",
    "\n",
    "    Arguments:\n",
    "        z - 2D tensorflow array of the snapshots on which to build the library. Shape is number of\n",
    "        time points by the number of state variables.\n",
    "        latent_dim - Integer, number of state variable in z.\n",
    "        poly_order - Integer, polynomial order to which to build the library. Max value is 5.\n",
    "        include_sine - Boolean, whether or not to include sine terms in the library. Default False.\n",
    "\n",
    "    Returns:\n",
    "        2D tensorflow array containing the constructed library. Shape is number of time points by\n",
    "        number of library functions. The number of library functions is determined by the number\n",
    "        of state variables of the input, the polynomial order, and whether or not sines are included.\n",
    "    \"\"\"\n",
    "\n",
    "    # add constant term to the set of equation\n",
    "    library = [tf.ones(tf.shape(z)[0])]\n",
    "\n",
    "    # add: x, y, z\n",
    "    for i in range(latent_dim):\n",
    "        library.append(z[:,i])\n",
    "\n",
    "    # add: xx + zz + yy + xy + xz + yz\n",
    "    if poly_order > 1:\n",
    "        print(\"call poly 1\")\n",
    "        for i in range(latent_dim):\n",
    "            for j in range(i,latent_dim):\n",
    "                library.append(z[:,i]*z[:,j])\n",
    "                #library.append(tf.math.multiply(z[:,i], z[:,j]))\n",
    "\n",
    "    # anologically to the comment above\n",
    "    if poly_order > 2:\n",
    "        print(\"call poly 2\")\n",
    "        for i in range(latent_dim):\n",
    "            for j in range(i,latent_dim):\n",
    "                for k in range(j,latent_dim):\n",
    "                    library.append(z[:,i]*z[:,j]*z[:,k])\n",
    "                    #library.append(tf.math.multiply(tf.math.multiply(z[:,i], z[:,j]), z[:,k]))\n",
    "\n",
    "    # anologically to the comment above\n",
    "    if poly_order > 3:\n",
    "        print(\"call poly 3\")\n",
    "        for i in range(latent_dim):\n",
    "            for j in range(i,latent_dim):\n",
    "                for k in range(j,latent_dim):\n",
    "                    for p in range(k,latent_dim):\n",
    "                        library.append(z[:,i]*z[:,j]*z[:,k]*z[:,p])\n",
    "                        #library.append(tf.math.multiply(tf.math.multiply(tf.math.multiply(z[:,i], z[:,j]), z[:,k]), z[:p]))\n",
    "\n",
    "    # anologically to the comment above\n",
    "    if poly_order > 4:\n",
    "        for i in range(latent_dim):\n",
    "            for j in range(i,latent_dim):\n",
    "                for k in range(j,latent_dim):\n",
    "                    for p in range(k,latent_dim):\n",
    "                        for q in range(p,latent_dim):\n",
    "                            library.append(z[:,i]*z[:,j]*z[:,k]*z[:,p]*z[:,q])\n",
    "                            #library.append(tf.math.multiply(tf.math.multiply(tf.math.multiply(tf.math.multiply(z[:,i], z[:,j]), z[:,k]), z[:p]), z[:q]))\n",
    "\n",
    "    # add: sin(x), sin(y), sin(z)\n",
    "    if include_sine:\n",
    "        for i in range(latent_dim):\n",
    "            library.append(np.sin(z[:,i]))\n",
    "            \n",
    "    return tf.convert_to_tensor(np.stack(library, axis = 1))\n",
    "\n",
    "r = sindy_library_tf(z, 3, 2, False)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "call poly 1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "source": [
    "Input(shape=(r.shape[0],)) "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 16) dtype=float32 (created by layer 'input_7')>"
      ]
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "def build_network_layers(\n",
    "    encoding_layers_size = [32, 28], \n",
    "    layers_params = [{'l1' : 0.0001, 'l2' : 0.0, 'dropout' : 0.0}, {}],\n",
    "    layers_default_params = {'l1' : 0.0001, 'l2' : 0.0, 'dropout' : 0.0, 'activation' : \"tanh\"},\n",
    "    loss = \"mse\",\n",
    "    optimizer =  tf.keras.optimizers.Adam,\n",
    "    learning_rate = 0.0001,\n",
    "    metrics = None\n",
    "    ) -> tf.keras.Model:\n",
    "\n",
    "    # initialize input layer \n",
    "    input_size = encoding_layers_size[0]\n",
    "    inputs = Input(shape=(input_size,))\n",
    "\n",
    "    # add empty dicionaries to layers_params to corecponds to the encoding_layers_size size\n",
    "    for _ in range(len(encoding_layers_size) - len(layers_params)):\n",
    "        layers_params.append({})\n",
    "\n",
    "    # remove firs instance \n",
    "    encoding_layers_size = encoding_layers_size[1:]\n",
    "\n",
    "    # fill missing values in layers_params using default values \n",
    "    layers_params = [{**layers_default_params, **x} for x in layers_params]\n",
    "    \n",
    "    #initalize arrays to hold encoding and decoding layers \n",
    "    encoders = []\n",
    "    decoders = []\n",
    "\n",
    "    for l_size, l_param in zip(encoding_layers_size, layers_params):\n",
    "        \n",
    "        encoders.append(Dropout(l_param['dropout']))\n",
    "\n",
    "        # construct encoding layer \n",
    "        encoding_layer = Dense(\n",
    "            units = l_size,\n",
    "            activation=l_param['activation'],\n",
    "            kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "            bias_initializer=tf.keras.initializers.Zeros(),\n",
    "            kernel_regularizer=tf.keras.regularizers.L1L2(l_param['l1'], l_param['l2']),\n",
    "        )\n",
    "        # add encoding layer to the array of encoding layer\n",
    "        encoders.append(encoding_layer)\n",
    "       \n",
    "        # construct decoding layer as dense transpose of encoding layer \n",
    "        decoders.append(DenseTranspose(dense=encoding_layer))\n",
    "\n",
    "    # reverse decoders array \n",
    "    decoders = decoders[::-1]\n",
    "\n",
    "    # stack layers to form auto-encoder architecture\n",
    "    stacked_layers = inputs\n",
    "    for layer in encoders + decoders:\n",
    "        stacked_layers = layer(stacked_layers)\n",
    "\n",
    "    model = tf.keras.Model(inputs, stacked_layers)\n",
    "\n",
    "    opt = optimizer(learning_rate=learning_rate)\n",
    "    if metrics == None:\n",
    "        model.compile(loss=loss, optimizer=opt)\n",
    "    else:\n",
    "        model.compile(loss=loss, optimizer=opt, metrics=metrics)\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "def tmp(tup : Optional[Tuple[str,str]]= (\"a\", \"b\")):\n",
    "    print(tup[0], tup[1])\n",
    "tmp()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "a b\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "source": [
    "from typing import List, Tuple, Union, Optional\n",
    "\n",
    "def build_autoencoder(\n",
    "    input_dim : int,\n",
    "    min_dim : int,\n",
    "    width : List[int],\n",
    "    transposed_decoder : Optional[bool] = True,\n",
    "    activation  = \"tanh\",\n",
    "    loss = \"mse\",\n",
    "    optimizer = \"Adam\",\n",
    "    metrics = [\"mae\", \"acc\"],\n",
    "    name : Tuple[str, str] = ('encoder', 'decoder')\n",
    "    ) -> Tuple[tf.keras.Model, tf.keras.Model, tf.keras.Model]:\n",
    "    \"\"\"\n",
    "    Unfortunately, at the time of writing this code\n",
    "    python typing did not support all keras types:\n",
    "    https://github.com/tensorflow/tensorflow/issues/46337\n",
    "\n",
    "    If if it will be resolved, types above can be improved:\n",
    "        activation : Optional[Union[tf.keras.activations, str]] = \"tanh\",\n",
    "        loss : Optional[Union[tf.keras.losses, str]] = \"mse\",\n",
    "        optimizer : Optional[Union[str, tf.keras.optimizers] = \"Adam\",\n",
    "        metrics : Optional[List[Union[str, tf.keras.metrics], tf.keras.metrics, str] = [\"mae\", \"acc\"]\n",
    "\n",
    "    !!! my previous kernal initializer was: tf.keras.initializers.RandomNormal(stddev=0.01)\n",
    "    \"\"\"\n",
    "    \n",
    "    name_encoder = 'endocer' if name[0]==None else name[0] \n",
    "    name_decoder = 'decoder' if name[1]==None else name[1]\n",
    "\n",
    "    encoder_layers = [Input(shape=(input_dim, ), name = name_encoder + '_input')]\n",
    "    decoder_layers = [Input(shape=(min_dim, ), name = name_decoder + '_input')]\n",
    "\n",
    "    for layer_index, layer_dim in enumerate(width):\n",
    "        # construct encoder layer \n",
    "        encoder_layers.append(\n",
    "            Dense(\n",
    "                units = layer_dim,\n",
    "                activation=activation, \n",
    "                kernel_initializer=tf.keras.initializers.GlorotUniform(),\n",
    "                bias_initializer=tf.keras.initializers.Zeros(),\n",
    "                name = name_encoder + \"_{}\".format(layer_index)\n",
    "                )\n",
    "            )\n",
    "    encoder_layers.append(\n",
    "        Dense(\n",
    "            units = min_dim,\n",
    "            activation=activation, \n",
    "            kernel_initializer=tf.keras.initializers.GlorotUniform(),\n",
    "            bias_initializer=tf.keras.initializers.Zeros(),\n",
    "            name = name_encoder + \"_output\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if transposed_decoder:\n",
    "        for layer_index, layer in enumerate(encoder_layers[::-1][:-1]):\n",
    "            # construct decoder layer\n",
    "            decoder_layers.append(\n",
    "                DenseTranspose(\n",
    "                    dense = layer,\n",
    "                    name = name_decoder + \"_{}\".format(layer_index)\n",
    "                    )\n",
    "                )\n",
    "    else:\n",
    "        for layer_index, layer in enumerate(width[::-1]):\n",
    "            # construct decoder layer \n",
    "            decoder_layers.append(\n",
    "                Dense(\n",
    "                    units = layer.input_shape[-1],\n",
    "                    activation=activation, \n",
    "                    kernel_initializer=tf.keras.initializers.GlorotUniform(),\n",
    "                    bias_initializer=tf.keras.initializers.Zeros(),\n",
    "                    name = name_decoder + \"_{}\".format(layer_index)\n",
    "                    )\n",
    "                )\n",
    "        decoder_layers.append(\n",
    "            Dense(\n",
    "                units = input_dim,\n",
    "                activation=activation, \n",
    "                kernel_initializer=tf.keras.initializers.GlorotUniform(),\n",
    "                bias_initializer=tf.keras.initializers.Zeros(),\n",
    "                name = name_decoder + \"_{}\".format(layer_index)\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # stack encoder layers into encoder\n",
    "    encoder_input = encoder_layers[0]\n",
    "    x = encoder_input\n",
    "    for encoder_layer in encoder_layers[1:]:\n",
    "        x = encoder_layer(x)\n",
    "    \n",
    "    # build encoder\n",
    "    encoder = tf.keras.Model(encoder_input, x)\n",
    "    encoder.compile(loss = loss, optimizer = optimizer, metrics=metrics)\n",
    "\n",
    "    # stack decoder layers into decoder\n",
    "    decoder_input = decoder_layers[0]\n",
    "    z = decoder_input\n",
    "    for decoder_layer in decoder_layers[1:]:\n",
    "        z = decoder_layer(z)\n",
    "    \n",
    "    # build decoder\n",
    "    decoder = tf.keras.Model(decoder_input, z)\n",
    "    decoder.compile(loss = loss, optimizer = optimizer, metrics=metrics)\n",
    "\n",
    "    # interation over encoder/decoder is intended to keep consistant layer naming\n",
    "    autoencoder_input = encoder_layers[0]\n",
    "    y = autoencoder_input\n",
    "    for autoencoder_layer in encoder_layers[1:] + decoder_layers[1:]:\n",
    "        y = autoencoder_layer(y)\n",
    "\n",
    "    # build autoencoder\n",
    "    autoencoder = tf.keras.Model(autoencoder_input, y)\n",
    "    autoencoder.compile(loss = loss, optimizer = optimizer, metrics=metrics)\n",
    "\n",
    "    return autoencoder, encoder, decoder\n",
    "\n",
    "a, e, d = build_autoencoder(32, 8, [24, 16])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "source": [
    "a.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_72\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "encoder_0 (Dense)            (None, 24)                792       \n",
      "_________________________________________________________________\n",
      "encoder_1 (Dense)            (None, 16)                400       \n",
      "_________________________________________________________________\n",
      "encoder_output (Dense)       (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "decoder_0 (DenseTranspose)   (None, 16)                152       \n",
      "_________________________________________________________________\n",
      "decoder_1 (DenseTranspose)   (None, 24)                424       \n",
      "_________________________________________________________________\n",
      "decoder_2 (DenseTranspose)   (None, 32)                824       \n",
      "=================================================================\n",
      "Total params: 1,400\n",
      "Trainable params: 1,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "input_l = Input(shape=(mod.layers[-1].output_shape[-1], ), name = '_input')\n",
    "x = DenseTranspose(dense = mod.layers[-1])(input_l)\n",
    "tf.keras.Model(input_l, x)\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7f7e1f2b7470>"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"Good autoencoder with nice dict args\"\"\"\n",
    "def build_autoencoder(\n",
    "    encoding_layers_size = [32, 28], \n",
    "    layers_params = [{'l1' : 0.0001, 'l2' : 0.0, 'dropout' : 0.0}, {}],\n",
    "    layers_default_params = {'l1' : 0.0001, 'l2' : 0.0, 'dropout' : 0.0, 'activation' : \"tanh\"},\n",
    "    loss = \"mse\",\n",
    "    optimizer =  tf.keras.optimizers.Adam,\n",
    "    learning_rate = 0.0001,\n",
    "    metrics = None\n",
    "    ):\n",
    "\n",
    "    # initialize input layer \n",
    "    input_size = encoding_layers_size[0]\n",
    "    inputs = Input(shape=(input_size,))\n",
    "\n",
    "    # add empty dicionaries to layers_params to corecponds to the encoding_layers_size size\n",
    "    for _ in range(len(encoding_layers_size) - len(layers_params)):\n",
    "        layers_params.append({})\n",
    "\n",
    "    # remove firs instance \n",
    "    encoding_layers_size = encoding_layers_size[1:]\n",
    "\n",
    "    # fill missing values in layers_params using default values \n",
    "    layers_params = [{**layers_default_params, **x} for x in layers_params]\n",
    "    \n",
    "    #initalize arrays to hold encoding and decoding layers \n",
    "    encoders = []\n",
    "    decoders = []\n",
    "\n",
    "    for l_size, l_param in zip(encoding_layers_size, layers_params):\n",
    "        \n",
    "        # if dropout is different than 0 then add dropout layer\n",
    "        #if l_param['dropout'] > 0.0:\n",
    "        encoders.append(Dropout(l_param['dropout']))\n",
    "\n",
    "\n",
    "        # construct encoding layer \n",
    "        encoding_layer = Dense(\n",
    "            units = l_size,\n",
    "            activation=l_param['activation'],\n",
    "            kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "            bias_initializer=tf.keras.initializers.Zeros(),\n",
    "            kernel_regularizer=tf.keras.regularizers.L1L2(l_param['l1'], l_param['l2']),\n",
    "        )\n",
    "        # add encoding layer to the array of encoding layer\n",
    "        encoders.append(encoding_layer)\n",
    "       \n",
    "        # construct decoding layer as dense transpose of encoding layer \n",
    "        decoders.append(DenseTranspose(dense=encoding_layer))\n",
    "\n",
    "    # remove dropout layer after the bottlenect layer\n",
    "    #if(type(encoders[-1]) == type(Dropout(0.0))):\n",
    "    #    encoders.pop()\n",
    "\n",
    "    # reverse decoders array \n",
    "    decoders = decoders[::-1]\n",
    "\n",
    "    # stack layers to form auto-encoder architecture\n",
    "    stacked_layers = inputs\n",
    "    for layer in encoders + decoders:\n",
    "        stacked_layers = layer(stacked_layers)\n",
    "\n",
    "    model = tf.keras.Model(inputs, stacked_layers)\n",
    "\n",
    "    opt = optimizer(learning_rate=learning_rate)\n",
    "    if metrics == None:\n",
    "        model.compile(loss=loss, optimizer=opt)\n",
    "    else:\n",
    "        model.compile(loss=loss, optimizer=opt, metrics=metrics)\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "\"\"\"Good model building\"\"\"\n",
    "\n",
    "from typing import List, Tuple, Union, Optional\n",
    "\n",
    "def build_autoencoder(\n",
    "    input_dim : int,\n",
    "    min_dim : int,\n",
    "    width : List[int],\n",
    "    transposed_decoder : Optional[bool] = True,\n",
    "    activation  = \"tanh\",\n",
    "    loss = \"mse\",\n",
    "    optimizer = \"Adam\",\n",
    "    metrics = [\"mae\", \"acc\"],\n",
    "    name : Tuple[str, str] = ('encoder', 'decoder')\n",
    "    ) -> Tuple[tf.keras.Model, tf.keras.Model, tf.keras.Model]:\n",
    "    \"\"\"\n",
    "    Unfortunately, at the time of writing this code\n",
    "    python typing did not support all keras types:\n",
    "    https://github.com/tensorflow/tensorflow/issues/46337\n",
    "\n",
    "    If if it will be resolved, types above can be improved:\n",
    "        activation : Optional[Union[tf.keras.activations, str]] = \"tanh\",\n",
    "        loss : Optional[Union[tf.keras.losses, str]] = \"mse\",\n",
    "        optimizer : Optional[Union[str, tf.keras.optimizers] = \"Adam\",\n",
    "        metrics : Optional[List[Union[str, tf.keras.metrics], tf.keras.metrics, str] = [\"mae\", \"acc\"]\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    name_encoder = 'endocer' if name[0]==None else name[0] \n",
    "    name_decoder = 'decoder' if name[1]==None else name[1]\n",
    "\n",
    "    encoder_layers = [Input(shape=(input_dim, ), name = name_encoder + '_input')]\n",
    "    decoder_layers = [Input(shape=(min_dim, ), name = name_decoder + '_input')]\n",
    "\n",
    "    for layer_index, layer_dim in enumerate(width):\n",
    "        # construct encoder layer \n",
    "        encoder_layers.append(\n",
    "            Dense(\n",
    "                units = layer_dim,\n",
    "                activation=activation, \n",
    "                kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "                bias_initializer=tf.keras.initializers.Zeros(),\n",
    "                name = name_encoder + \"_{}\".format(layer_index)\n",
    "                )\n",
    "            )\n",
    "    encoder_layers.append(\n",
    "        Dense(\n",
    "            units = min_dim,\n",
    "            activation=activation, \n",
    "            kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "            bias_initializer=tf.keras.initializers.Zeros(),\n",
    "            name = name_encoder + \"_output\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if transposed_decoder:\n",
    "        for layer_index, layer in enumerate(encoder_layers[::-1][:-1]):\n",
    "            # construct decoder layer\n",
    "            decoder_layers.append(\n",
    "                DenseTranspose(\n",
    "                    dense = layer,\n",
    "                    name = name_decoder + \"_{}\".format(layer_index)\n",
    "                    )\n",
    "                )\n",
    "    else:\n",
    "        for layer_index, layer in enumerate(width[::-1]):\n",
    "            # construct decoder layer \n",
    "            decoder_layers.append(\n",
    "                Dense(\n",
    "                    units = layer.input_shape[-1],\n",
    "                    activation=activation, \n",
    "                    kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "                    bias_initializer=tf.keras.initializers.Zeros(),\n",
    "                    name = name_decoder + \"_{}\".format(layer_index)\n",
    "                    )\n",
    "                )\n",
    "        decoder_layers.append(\n",
    "            Dense(\n",
    "                units = input_dim,\n",
    "                activation=activation, \n",
    "                kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "                bias_initializer=tf.keras.initializers.Zeros(),\n",
    "                name = name_decoder + \"_{}\".format(layer_index)\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # stack encoder layers into encoder\n",
    "    encoder_input = encoder_layers[0]\n",
    "    x = encoder_input\n",
    "    for encoder_layer in encoder_layers[1:]:\n",
    "        x = encoder_layer(x)\n",
    "    \n",
    "    # build encoder\n",
    "    encoder = tf.keras.Model(encoder_input, x)\n",
    "    encoder.compile(loss = loss, optimizer = optimizer, metrics=metrics)\n",
    "\n",
    "    # stack decoder layers into decoder\n",
    "    decoder_input = decoder_layers[0]\n",
    "    z = decoder_input\n",
    "    for decoder_layer in decoder_layers[1:]:\n",
    "        z = decoder_layer(z)\n",
    "    \n",
    "    # build decoder\n",
    "    decoder = tf.keras.Model(decoder_input, z)\n",
    "    decoder.compile(loss = loss, optimizer = optimizer, metrics=metrics)\n",
    "\n",
    "    # interation over encoder/decoder is intended to keep consistant layer naming\n",
    "    autoencoder_input = encoder_layers[0]\n",
    "    y = autoencoder_input\n",
    "    for autoencoder_layer in encoder_layers[1:] + decoder_layers[1:]:\n",
    "        y = autoencoder_layer(y)\n",
    "\n",
    "    # build autoencoder\n",
    "    autoencoder = tf.keras.Model(autoencoder_input, y)\n",
    "    autoencoder.compile(loss = loss, optimizer = optimizer, metrics=metrics)\n",
    "\n",
    "    return autoencoder, encoder, decoder\n",
    "\n",
    "a, e, d = build_autoencoder(32, 8, [24, 16])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "def build_decoder_from_encoder(encoder: tf.keras.models.Model, name : str = \"decoder\"):\n",
    "    # reversed list of encoder layers\n",
    "    decoder_layers = encoder.layers[::-1]\n",
    "    input_dim = decoder_layers[0].output_shape[-1]\n",
    "    print(decoder_layers)\n",
    "\n",
    "    input_layer = Input(shape=(None, input_dim), name = name + '_input')\n",
    "\n",
    "    x = input_layer\n",
    "    for layer_index, decoder_layer in enumerate(decoder_layers):\n",
    "        #  construct decoding layer that is transposed encoding layer\n",
    "        print(decoder_layer.output_shape)\n",
    "        x = DenseTranspose(\n",
    "            decoder_layer\n",
    "        )(x)\n",
    "\n",
    "    output_layer = DenseTranspose(\n",
    "        decoder_layers[-1]\n",
    "    )(x)\n",
    "\n",
    "    model = tf.keras.Model(input_layer, output_layer)\n",
    "    return model \n",
    "build_decoder_from_encoder(mod)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[<keras.layers.core.Dense object at 0x7f7e1f55ab00>, <keras.layers.core.Dense object at 0x7f7e1f55a3c8>, <keras.layers.core.Dense object at 0x7f7e1f5dbc18>, <keras.engine.input_layer.InputLayer object at 0x7f7e1f5db7b8>]\n",
      "(None, 8)\n",
      "(None, 16)\n",
      "(None, 24)\n",
      "[(None, 32)]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "Dimension value must be integer or None or have an __index__ method, got value '(None, 32)' with type '<class 'tuple'>'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-ed461f61129b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mbuild_decoder_from_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-63-ed461f61129b>\u001b[0m in \u001b[0;36mbuild_decoder_from_encoder\u001b[0;34m(encoder, name)\u001b[0m\n\u001b[1;32m     13\u001b[0m         x = DenseTranspose(\n\u001b[1;32m     14\u001b[0m             \u001b[0mdecoder_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         )(x)\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     output_layer = DenseTranspose(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 977\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1113\u001b[0m       \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1115\u001b[0;31m           inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    884\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m           \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2657\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SindyAutoencoders/examples/lorenz/shallowNet/shallowNet.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, batch_input_shape)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDenseTranspose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_input_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"bias\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"zeros\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_input_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m         caching_device=caching_device)\n\u001b[0m\u001b[1;32m    664\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m       \u001b[0;31m# TODO(fchollet): in the future, this should be handled at the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    816\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         **kwargs_for_getter)\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36mmake_variable\u001b[0;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mvariable_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m   \u001b[0mvariable_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0muse_resource\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dims)\u001b[0m\n\u001b[1;32m    763\u001b[0m     \"\"\"\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Most common case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mDimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    763\u001b[0m     \"\"\"\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Most common case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mDimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    207\u001b[0m             TypeError(\"Dimension value must be integer or None or have \"\n\u001b[1;32m    208\u001b[0m                       \u001b[0;34m\"an __index__ method, got value '{0!r}' with type '{1!r}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m                       .format(value, type(value))), None)\n\u001b[0m\u001b[1;32m    210\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dimension %d must be >= 0\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Dimension value must be integer or None or have an __index__ method, got value '(None, 32)' with type '<class 'tuple'>'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-9e590dc3afd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbuild_decoder_from_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-40-046039dc3dcf>\u001b[0m in \u001b[0;36mbuild_decoder_from_encoder\u001b[0;34m(encoder, name)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;31m#  construct decoding layer that is transposed encoding layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         x = DenseTranspose(\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "def build_autoencoder(\n",
    "    encoding_layers_size = [32, 28], \n",
    "    layers_params = [{'l1' : 0.0001, 'l2' : 0.0, 'dropout' : 0.0}, {}],\n",
    "    layers_default_params = {'l1' : 0.0001, 'l2' : 0.0, 'dropout' : 0.0, 'activation' : \"tanh\"},\n",
    "    loss = \"mse\",\n",
    "    optimizer =  tf.keras.optimizers.Adam,\n",
    "    learning_rate = 0.0001,\n",
    "    metrics = None\n",
    "    ) -> tf.keras.Model:\n",
    "\n",
    "    # initialize input layer \n",
    "    input_size = encoding_layers_size[0]\n",
    "    inputs = Input(shape=(input_size,))\n",
    "\n",
    "    # add empty dicionaries to layers_params to corecponds to the encoding_layers_size size\n",
    "    for _ in range(len(encoding_layers_size) - len(layers_params)):\n",
    "        layers_params.append({})\n",
    "\n",
    "    # remove firs instance \n",
    "    encoding_layers_size = encoding_layers_size[1:]\n",
    "\n",
    "    # fill missing values in layers_params using default values \n",
    "    layers_params = [{**layers_default_params, **x} for x in layers_params]\n",
    "    \n",
    "    #initalize arrays to hold encoding and decoding layers \n",
    "    encoders = []\n",
    "    decoders = []\n",
    "\n",
    "    for l_size, l_param in zip(encoding_layers_size, layers_params):\n",
    "        \n",
    "        encoders.append(Dropout(l_param['dropout']))\n",
    "\n",
    "        # construct encoding layer \n",
    "        encoding_layer = Dense(\n",
    "            units = l_size,\n",
    "            activation=l_param['activation'],\n",
    "            kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01),\n",
    "            bias_initializer=tf.keras.initializers.Zeros(),\n",
    "            kernel_regularizer=tf.keras.regularizers.L1L2(l_param['l1'], l_param['l2']),\n",
    "        )\n",
    "        # add encoding layer to the array of encoding layer\n",
    "        encoders.append(encoding_layer)\n",
    "       \n",
    "        # construct decoding layer as dense transpose of encoding layer \n",
    "        decoders.append(DenseTranspose(dense=encoding_layer))\n",
    "\n",
    "    # reverse decoders array \n",
    "    decoders = decoders[::-1]\n",
    "\n",
    "    # stack layers to form auto-encoder architecture\n",
    "    stacked_layers = inputs\n",
    "    for layer in encoders + decoders:\n",
    "        stacked_layers = layer(stacked_layers)\n",
    "\n",
    "    model = tf.keras.Model(inputs, stacked_layers)\n",
    "\n",
    "    opt = optimizer(learning_rate=learning_rate)\n",
    "    if metrics == None:\n",
    "        model.compile(loss=loss, optimizer=opt)\n",
    "    else:\n",
    "        model.compile(loss=loss, optimizer=opt, metrics=metrics)\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "build_autoencoder().summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 28)                924       \n",
      "_________________________________________________________________\n",
      "dense_transpose (DenseTransp (None, 32)                956       \n",
      "=================================================================\n",
      "Total params: 956\n",
      "Trainable params: 956\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "def define_loss(network, params):\n",
    "    \"\"\"\n",
    "    Create the loss functions.\n",
    "\n",
    "    Arguments:\n",
    "        network - Dictionary object containing the elements of the network architecture.\n",
    "        This will be the output of the full_network() function.\n",
    "    \"\"\"\n",
    "    x = network['x']\n",
    "    x_decode = network['x_decode']\n",
    "    if params['model_order'] == 1:\n",
    "        dz = network['dz']\n",
    "        dz_predict = network['dz_predict']\n",
    "        dx = network['dx']\n",
    "        dx_decode = network['dx_decode']\n",
    "    else:\n",
    "        ddz = network['ddz']\n",
    "        ddz_predict = network['ddz_predict']\n",
    "        ddx = network['ddx']\n",
    "        ddx_decode = network['ddx_decode']\n",
    "    sindy_coefficients = params['coefficient_mask']*network['sindy_coefficients']\n",
    "\n",
    "    losses = {}\n",
    "    losses['decoder'] = tf.math.reduce_mean((x - x_decode)**2)\n",
    "    if params['model_order'] == 1:\n",
    "        losses['sindy_z'] = tf.math.reduce_mean((dz - dz_predict)**2)\n",
    "        losses['sindy_x'] = tf.math.reduce_mean((dx - dx_decode)**2)\n",
    "    else:\n",
    "        losses['sindy_z'] = tf.math.reduce_mean((ddz - ddz_predict)**2)\n",
    "        losses['sindy_x'] = tf.math.reduce_mean((ddx - ddx_decode)**2)\n",
    "    losses['sindy_regularization'] = tf.math.reduce_mean(tf.math.abs(sindy_coefficients))\n",
    "    loss = params['loss_weight_decoder'] * losses['decoder'] \\\n",
    "           + params['loss_weight_sindy_z'] * losses['sindy_z'] \\\n",
    "           + params['loss_weight_sindy_x'] * losses['sindy_x'] \\\n",
    "           + params['loss_weight_sindy_regularization'] * losses['sindy_regularization']\n",
    "\n",
    "    loss_refinement = params['loss_weight_decoder'] * losses['decoder'] \\\n",
    "                      + params['loss_weight_sindy_z'] * losses['sindy_z'] \\\n",
    "                      + params['loss_weight_sindy_x'] * losses['sindy_x']\n",
    "\n",
    "    return loss, losses, loss_refinement"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "input_size = 32\n",
    "set_size = 100\n",
    "compression = 0.8\n",
    "reg_cof = 1e-3\n",
    "epochs = 40\n",
    "batch = 4\n",
    "\n",
    "mod = build_autoencoder(\n",
    "    encoding_layers_size = [32, 25], \n",
    "    layers_params = [{'l1' : 1e-3, 'l2' : 0.0, 'dropout' : 0.0}, {}],\n",
    "    layers_default_params = {'l1' : 0.0001, 'l2' : 0.0, 'dropout' : 0.0, 'activation' : \"tanh\"},\n",
    "    loss = \"mse\",\n",
    "    optimizer =  tf.keras.optimizers.Adam,\n",
    "    learning_rate = 0.01,\n",
    "    metrics = None)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "mod.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 25)                825       \n",
      "_________________________________________________________________\n",
      "dense_transpose_1 (DenseTran (None, 32)                857       \n",
      "=================================================================\n",
      "Total params: 857\n",
      "Trainable params: 857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "\n",
    "def build_network_layers(input, input_dim, output_dim, widths, activation, name):\n",
    "    \"\"\"\n",
    "    Construct one portion of the network (either encoder or decoder).\n",
    "\n",
    "    Arguments:\n",
    "        input - 2D tensorflow array, input to the network (shape is [?,input_dim])\n",
    "        input_dim - Integer, number of state variables in the input to the first layer\n",
    "        output_dim - Integer, number of state variables to output from the final layer\n",
    "        widths - List of integers representing how many units are in each network layer\n",
    "        activation - Tensorflow function to be used as the activation function at each layer\n",
    "        name - String, prefix to be used in naming the tensorflow variables\n",
    "\n",
    "    Returns:\n",
    "        input - Tensorflow array, output of the network layers (shape is [?,output_dim])\n",
    "        weights - List of tensorflow arrays containing the network weights\n",
    "        biases - List of tensorflow arrays containing the network biases\n",
    "    \"\"\"\n",
    "    weights = []\n",
    "    biases = []\n",
    "    last_width=input_dim\n",
    "    for i,n_units in enumerate(widths):\n",
    "        W = tf.get_variable(name+'_W'+str(i), shape=[last_width,n_units],\n",
    "            initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b = tf.get_variable(name+'_b'+str(i), shape=[n_units],\n",
    "            initializer=tf.constant_initializer(0.0))\n",
    "        input = tf.matmul(input, W) + b\n",
    "        if activation is not None:\n",
    "            input = activation(input)\n",
    "        last_width = n_units\n",
    "        weights.append(W)\n",
    "        biases.append(b)\n",
    "    W = tf.get_variable(name+'_W'+str(len(widths)), shape=[last_width,output_dim],\n",
    "        initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b = tf.get_variable(name+'_b'+str(len(widths)), shape=[output_dim],\n",
    "        initializer=tf.constant_initializer(0.0))\n",
    "    input = tf.matmul(input,W) + b\n",
    "    weights.append(W)\n",
    "    biases.append(b)\n",
    "    return input, weights, biases"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "def sindy_library_tf(z, latent_dim, poly_order, include_sine=False):\n",
    "    \"\"\"\n",
    "    Build the SINDy library.\n",
    "\n",
    "    Arguments:\n",
    "        z - 2D tensorflow array of the snapshots on which to build the library. Shape is number of\n",
    "        time points by the number of state variables.\n",
    "        latent_dim - Integer, number of state variable in z.\n",
    "        poly_order - Integer, polynomial order to which to build the library. Max value is 5.\n",
    "        include_sine - Boolean, whether or not to include sine terms in the library. Default False.\n",
    "\n",
    "    Returns:\n",
    "        2D tensorflow array containing the constructed library. Shape is number of time points by\n",
    "        number of library functions. The number of library functions is determined by the number\n",
    "        of state variables of the input, the polynomial order, and whether or not sines are included.\n",
    "    \"\"\"\n",
    "\n",
    "    # add constant term to the set of equation\n",
    "    library = [tf.ones(tf.shape(z)[0])]\n",
    "\n",
    "    # add: x, y, z\n",
    "    for i in range(latent_dim):\n",
    "        library.append(z[:,i])\n",
    "\n",
    "    # add: xx + zz + yy + xy + xz + yz\n",
    "    if poly_order > 1:\n",
    "        print(\"call poly 1\")\n",
    "        for i in range(latent_dim):\n",
    "            for j in range(i,latent_dim):\n",
    "                library.append(tf.math.multiply(z[:,i], z[:,j]))\n",
    "\n",
    "    # anologically to the comment above\n",
    "    if poly_order > 2:\n",
    "        print(\"call poly 2\")\n",
    "        for i in range(latent_dim):\n",
    "            for j in range(i,latent_dim):\n",
    "                for k in range(j,latent_dim):\n",
    "                    library.append(z[:,i]*z[:,j]*z[:,k])\n",
    "\n",
    "    # anologically to the comment above\n",
    "    if poly_order > 3:\n",
    "        print(\"call poly 3\")\n",
    "        for i in range(latent_dim):\n",
    "            for j in range(i,latent_dim):\n",
    "                for k in range(j,latent_dim):\n",
    "                    for p in range(k,latent_dim):\n",
    "                        library.append(z[:,i]*z[:,j]*z[:,k]*z[:,p])\n",
    "    \n",
    "    # anologically to the comment above\n",
    "    if poly_order > 4:\n",
    "        for i in range(latent_dim):\n",
    "            for j in range(i,latent_dim):\n",
    "                for k in range(j,latent_dim):\n",
    "                    for p in range(k,latent_dim):\n",
    "                        for q in range(p,latent_dim):\n",
    "                            library.append(z[:,i]*z[:,j]*z[:,k]*z[:,p]*z[:,q])\n",
    "    \n",
    "    # add: sin(x), sin(y), sin(z)\n",
    "    if include_sine:\n",
    "        for i in range(latent_dim):\n",
    "            library.append(tf.sin(z[:,i]))\n",
    "\n",
    "    return tf.stack(library, axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.9",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}